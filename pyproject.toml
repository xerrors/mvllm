[project]
name = "vllm-router"
version = "0.1.0"
description = "A FastAPI-based load balancer for vLLM servers with OpenAI-compatible API"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "fastapi>=0.104.0",
    "uvicorn>=0.24.0",
    "httpx>=0.25.0",
    "toml>=0.10.2",
    "pydantic>=2.5.0",
    "openai",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["app"]

[project.scripts]
vllm-router = "app.main:main"
