"""
Queue management for vLLM Router
"""

import asyncio
import random
import sys
import uuid
from datetime import datetime
from typing import Dict, Optional
from loguru import logger
from rich.console import Console
from rich.live import Live
from rich.table import Table
from rich.panel import Panel
from rich.text import Text
from rich.progress import Progress, SpinnerColumn, TextColumn
from .config import Config, get_config

class QueueManager:
    def __init__(self, config: Config):
        self.config = config
        self.global_queue = asyncio.Queue()  # å…¨å±€é˜Ÿåˆ—ï¼Œæ‰€æœ‰è¯·æ±‚æŒ‰FIFOé¡ºåºå¤„ç†
        self.server_loads: Dict[str, int] = {}  # æœåŠ¡å™¨å½“å‰å¤„ç†ä¸­çš„è¯·æ±‚æ•°é‡
        self.server_locks: Dict[str, asyncio.Lock] = {}  # æ¯ä¸ªæœåŠ¡å™¨çš„é”
        self.lock = asyncio.Lock()  # å…¨å±€é”
        self.active_requests: Dict[str, str] = {}  # request_id -> server_url æ˜ å°„
        self.request_events: Dict[str, asyncio.Event] = {}  # è¯·æ±‚åˆ†å‘äº‹ä»¶
        self.completed_requests = asyncio.Queue()  # å·²å®Œæˆçš„è¯·æ±‚é˜Ÿåˆ—

        # Rich console for status display - force stdout to avoid conflicts with loguru
        self.console = Console(file=sys.stdout)
        self.live_display = None

        # åˆå§‹åŒ–æœåŠ¡å™¨çŠ¶æ€
        self._initialize_servers()

        # å¯åŠ¨åˆ†å‘å·¥ä½œå™¨
        self._worker_started = False

    def _initialize_servers(self):
        """åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡å™¨çŠ¶æ€"""
        for server in self.config.servers:
            self.server_loads[server.url] = 0
            self.server_locks[server.url] = asyncio.Lock()

    async def add_request(self, request_data: dict) -> str:
        """æ·»åŠ è¯·æ±‚åˆ°å…¨å±€é˜Ÿåˆ—å¹¶è¿”å›žè¯·æ±‚ID"""
        request_id = request_data['request_id'] # Use the request_id from request_data

        # æ·»åŠ åˆ°å…¨å±€é˜Ÿåˆ—
        await self.global_queue.put(request_data)

        # åˆ›å»ºè¯·æ±‚äº‹ä»¶
        self.request_events[request_id] = asyncio.Event()

        logger.info(f"Request {request_id} added to global queue. Queue size: {self.global_queue.qsize()}")

        # å¯åŠ¨åˆ†å‘ä»»åŠ¡ï¼ˆå¦‚æžœè¿˜æ²¡æœ‰å¯åŠ¨ï¼‰
        if not getattr(self, '_worker_started', False):
            self._worker_started = True
            logger.info("Starting dispatch worker for the first time...")
            asyncio.create_task(self._dispatch_worker())
        return request_id

    async def _dispatch_worker(self):
        """æŒç»­å¤„ç†å…¨å±€é˜Ÿåˆ—ä¸­çš„è¯·æ±‚åˆ†å‘"""
        logger.info("Starting dispatch worker...")

        while True:
            try:
                # ä»Žå…¨å±€é˜Ÿåˆ—èŽ·å–è¯·æ±‚
                request_data = await self.global_queue.get()
                request_id = request_data.get('request_id')

                logger.info(f"Dispatch worker processing request {request_id}, queue size: {self.global_queue.qsize()}")

                # é€‰æ‹©æœ€ä¼˜æœåŠ¡å™¨
                server_url = await self._select_optimal_server()

                if server_url:
                    # åˆ†å‘è¯·æ±‚åˆ°æœåŠ¡å™¨
                    await self._dispatch_to_server(request_id, server_url, request_data)
                    logger.info(f"Request {request_id} dispatched to {server_url}")
                else:
                    logger.warning(f"No servers have available capacity for request {request_id}. Re-queueing.")
                    # ç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡æ–°å°è¯•
                    await asyncio.sleep(0.1) # Small delay before re-queueing
                    # å°†è¯·æ±‚æ”¾å›žé˜Ÿåˆ—å°¾éƒ¨
                    await self.global_queue.put(request_data)

            except asyncio.CancelledError:
                logger.info("Dispatch worker cancelled")
                break
            except Exception as e:
                logger.error(f"Error in dispatch worker: {e}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªè¯·æ±‚ï¼Œä¸è¦å› ä¸ºä¸€ä¸ªé”™è¯¯è€Œåœæ­¢
                continue

    async def _select_optimal_server(self) -> Optional[str]:
        """é€‰æ‹©å½“å‰è´Ÿè½½æœ€å°çš„å¥åº·æœåŠ¡å™¨ï¼Œè€ƒè™‘æœ€å¤§å¹¶å‘é™åˆ¶"""
        healthy_servers = self.config.get_healthy_servers()

        logger.debug(f"Selecting optimal server from {len(healthy_servers)} healthy servers")

        if not healthy_servers:
            logger.warning("No healthy servers available")
            return None

        # æ‰¾åˆ°æœ‰å¯ç”¨å®¹é‡çš„æœåŠ¡å™¨ï¼Œè®¡ç®—è´Ÿè½½ç™¾åˆ†æ¯”
        available_servers = []
        for server in healthy_servers:
            current_load = self.server_loads.get(server.url, 0)
            max_concurrent = server.max_concurrent_requests
            available_capacity = max_concurrent - current_load
            load_percentage = current_load / max_concurrent if max_concurrent > 0 else 0

            logger.debug(f"Server {server.url} has load {current_load}/{max_concurrent} ({load_percentage:.1%}) (available: {available_capacity})")

            if available_capacity > 0:
                available_servers.append((server.url, current_load, load_percentage))

        if not available_servers:
            logger.debug("No servers have available capacity")
            return None

        # é€‰æ‹©è´Ÿè½½ç™¾åˆ†æ¯”æœ€å°çš„æœåŠ¡å™¨
        min_load_percentage = min(load_pct for _, _, load_pct in available_servers)
        selected_servers = [url for url, _, load_pct in available_servers if load_pct == min_load_percentage]

        logger.debug(f"Selected servers with min load percentage {min_load_percentage:.1%}: {selected_servers}")

        # å¦‚æžœæœ‰å¤šä¸ªæœåŠ¡å™¨è´Ÿè½½ç›¸åŒï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª
        if selected_servers:
            selected = random.choice(selected_servers)
            logger.info(f"Chose server {selected}")
            return selected

        logger.warning("No servers selected despite having available capacity")
        return None

    async def _dispatch_to_server(self, request_id: str, server_url: str, request_data: dict):
        """å°†è¯·æ±‚åˆ†å‘åˆ°æŒ‡å®šæœåŠ¡å™¨"""
        async with self.server_locks[server_url]:
            # æ›´æ–°æœåŠ¡å™¨è´Ÿè½½
            self.server_loads[server_url] += 1
            self.active_requests[request_id] = server_url

        # è§¦å‘è¯·æ±‚åˆ†å‘äº‹ä»¶
        if request_id in self.request_events:
            self.request_events[request_id].set()

        logger.info(f"Request {request_id} dispatched to {server_url}. Current load: {self.server_loads[server_url]}")

    async def wait_for_dispatch(self, request_id: str, timeout: float = 30.0) -> Optional[str]:
        """ç­‰å¾…è¯·æ±‚è¢«åˆ†å‘åˆ°æŸä¸ªæœåŠ¡å™¨"""
        try:
            if request_id not in self.request_events:
                logger.error(f"Request {request_id} not found in request events")
                return None

            # ç­‰å¾…åˆ†å‘äº‹ä»¶
            await asyncio.wait_for(self.request_events[request_id].wait(), timeout=timeout)
            return self.active_requests.get(request_id)

        except asyncio.TimeoutError:
            logger.error(f"Request {request_id} dispatch timeout after {timeout}s")
            return None

    async def redistribute_request(self, request_id: str, request_data: dict):
        """Re-queues a failed request for redistribution to another server."""
        logger.info(f"Re-queueing request {request_id} for redistribution.")
        # Re-create the event for this request_id, as the previous one might have been set or cancelled.
        self.request_events[request_id] = asyncio.Event()
        # Put it back in the global queue
        await self.global_queue.put(request_data)

    async def notify_request_completed(self, request_id: str):
        """é€šçŸ¥è¯·æ±‚å·²å®Œæˆï¼Œå‡å°‘æœåŠ¡å™¨è´Ÿè½½"""
        logger.debug(f"Notifying request {request_id} completed")
        if request_id not in self.active_requests:
            logger.warning(f"Request {request_id} not found in active requests")
            return

        server_url = self.active_requests[request_id]

        async with self.server_locks[server_url]:
            # å‡å°‘æœåŠ¡å™¨è´Ÿè½½
            if self.server_loads[server_url] > 0:
                self.server_loads[server_url] -= 1

            # æ¸…ç†è¯·æ±‚è®°å½•
            del self.active_requests[request_id]
            if request_id in self.request_events:
                del self.request_events[request_id]

        logger.info(f"Request {request_id} completed on {server_url}. Current load: {self.server_loads[server_url]}")

    async def release_request(self, request_id: str) -> bool:
        """æ‰‹åŠ¨é‡Šæ”¾è¯·æ±‚ï¼ˆå½“è¯·æ±‚çœŸæ­£å®Œæˆæ—¶è°ƒç”¨ï¼‰"""
        await self.notify_request_completed(request_id)
        return True

    def get_queue_stats(self) -> dict:
        """èŽ·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        healthy_servers = self.config.get_healthy_servers()
        return {
            "global_queue_size": self.global_queue.qsize(),
            "active_requests": len(self.active_requests),
            "server_loads": {
                server.url: {
                    "current": self.server_loads.get(server.url, 0),
                    "max": server.max_concurrent_requests,
                    "available": server.max_concurrent_requests - self.server_loads.get(server.url, 0)
                }
                for server in self.config.servers
            },
            "healthy_servers": len(healthy_servers),
            "total_servers": len(self.config.servers)
        }

    def create_status_panel(self):
        """åˆ›å»ºç¾Žè§‚çš„çŠ¶æ€é¢æ¿"""
        stats = self.get_queue_stats()
        global_queue_size = stats["global_queue_size"]
        active_requests = stats["active_requests"]

        # åˆ›å»ºä¸»è¡¨æ ¼
        table = Table(show_header=True, header_style="bold blue", box=None)
        table.add_column("æ—¶é—´", style="cyan", no_wrap=True)
        table.add_column("é˜Ÿåˆ—", style="green", justify="right")
        table.add_column("å¤„ç†ä¸­", style="yellow", justify="right")
        table.add_column("æœåŠ¡å™¨çŠ¶æ€", style="magenta")

        # æœåŠ¡å™¨è´Ÿè½½ä¿¡æ¯
        server_info = []
        healthy_servers = stats["healthy_servers"]
        total_servers = stats["total_servers"]

        for server_url, load_info in stats["server_loads"].items():
            server_name = server_url.split("://")[-1].split(":")[0]
            current = load_info["current"]
            max_concurrent = load_info["max"]
            available = load_info["available"]

            # æ ¹æ®è´Ÿè½½çŠ¶æ€è®¾ç½®é¢œè‰²
            if current == 0:
                status_icon = "âœ…"
            elif available == 0:
                status_icon = "ðŸ”´"
            else:
                status_icon = "ðŸŸ¡"

            server_info.append(f"{status_icon} {server_name}: {current}/{max_concurrent}")

        server_status = "\n".join(server_info) if server_info else "æ— æœåŠ¡å™¨"

        # æ·»åŠ æ•°æ®è¡Œ
        table.add_row(
            f"{datetime.now().strftime('%H:%M:%S')}",
            f"{global_queue_size}",
            f"{active_requests}",
            server_status
        )

        # åˆ›å»ºè¿›åº¦æ¡æ˜¾ç¤ºå¥åº·çŠ¶æ€
        healthy_ratio = healthy_servers / total_servers if total_servers > 0 else 0
        health_status = "å¥åº·" if healthy_ratio >= 0.8 else "éƒ¨åˆ†å¥åº·" if healthy_ratio >= 0.5 else "ä¸å¥åº·"

        # åˆ›å»ºä¸»é¢æ¿
        panel = Panel(
            table,
            title=f"[bold blue]vLLM Router[/bold blue]",
            subtitle=f"å¥åº·åº¦: {healthy_servers}/{total_servers} | {health_status}",
            border_style="blue"
        )

        return panel

    async def start_status_monitor(self, interval: int = 5, use_rich: bool = True):
        """å¯åŠ¨é˜Ÿåˆ—çŠ¶æ€ç›‘æŽ§ä»»åŠ¡"""
        if not use_rich:
            logger.info("çŠ¶æ€ç›‘æŽ§å·²å¯åŠ¨ - ä½¿ç”¨ç®€å•æ¨¡å¼ (æ— Rich Live)")
            async def simple_monitor_loop():
                try:
                    while True:
                        # For simple mode, just log the stats or print a single line
                        stats = self.get_queue_stats()
                        logger.opt(extra={"status_update": True}).info(f"Queue Status: Global Queue: {stats['global_queue_size']}, Active: {stats['active_requests']}")
                        await asyncio.sleep(interval)
                except asyncio.CancelledError:
                    logger.info("ç®€å•çŠ¶æ€ç›‘æŽ§å·²åœæ­¢")
                except Exception as e:
                    logger.error(f"ç®€å•çŠ¶æ€ç›‘æŽ§å‡ºé”™: {e}")
            self.monitor_task = asyncio.create_task(simple_monitor_loop())
            return

        logger.info("çŠ¶æ€ç›‘æŽ§å·²å¯åŠ¨ - ä½¿ç”¨Rich Liveæ¨¡å¼")

        async def rich_monitor_loop():
            try:
                with Live(self.create_status_panel(), refresh_per_second=1, console=self.console) as live:
                    while True:
                        live.update(self.create_status_panel())
                        await asyncio.sleep(interval)
            except asyncio.CancelledError:
                logger.info("Rich LiveçŠ¶æ€ç›‘æŽ§å·²åœæ­¢")
            except Exception as e:
                logger.error(f"Rich LiveçŠ¶æ€ç›‘æŽ§å‡ºé”™: {e}")

        self.monitor_task = asyncio.create_task(rich_monitor_loop())
        logger.info(f"é˜Ÿåˆ—çŠ¶æ€ç›‘æŽ§å·²å¯åŠ¨ï¼Œé—´éš”: {interval}ç§’")

    async def stop_status_monitor(self):
        """åœæ­¢é˜Ÿåˆ—çŠ¶æ€ç›‘æŽ§ä»»åŠ¡"""
        if hasattr(self, 'monitor_task') and self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass
            logger.info("é˜Ÿåˆ—çŠ¶æ€ç›‘æŽ§å·²åœæ­¢")

# å…¨å±€é˜Ÿåˆ—ç®¡ç†å™¨å®žä¾‹
_global_queue_manager = None

def get_config():
    """Import get_config to avoid circular import"""
    from .config import get_config
    return get_config()

def get_queue_manager() -> QueueManager:
    """Get the global queue manager instance (singleton)"""
    global _global_queue_manager
    if _global_queue_manager is None:
        config = get_config()
        _global_queue_manager = QueueManager(config)
        logger.info("Global queue manager instance created")
    return _global_queue_manager
