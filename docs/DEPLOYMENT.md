# vLLM Router éƒ¨ç½²æŒ‡å—

## ğŸš€ å¿«é€Ÿéƒ¨ç½²

### åŸºç¡€ç¯å¢ƒå‡†å¤‡

#### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 20.04+), macOS 10.15+, Windows 10+
- **Python**: 3.8+
- **å†…å­˜**: æœ€å°‘ 512MB RAM
- **ç£ç›˜**: æœ€å°‘ 1GB å¯ç”¨ç©ºé—´
- **ç½‘ç»œ**: èƒ½è®¿é—® vLLM æœåŠ¡å™¨çš„ç½‘ç»œç¯å¢ƒ

#### å®‰è£…ä¾èµ–

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/xerrors/vllm-router.git
cd vllm-router

# ä½¿ç”¨ uv å®‰è£…ä¾èµ– (æ¨è)
uv sync

# æˆ–ä½¿ç”¨ pip å®‰è£…
pip install -r requirements.txt
```

## ğŸ“‹ é…ç½®æ–‡ä»¶ç¤ºä¾‹

### åŸºç¡€é…ç½® (servers.toml)

```toml
[servers]
servers = [
    # å¼€å‘ç¯å¢ƒé…ç½®
    { url = "http://localhost:8081", max_concurrent_requests = 2 },
    { url = "http://localhost:8082", max_concurrent_requests = 2 },
]

[config]
# å¥åº·æ£€æŸ¥é…ç½®
health_check_interval = 10
health_check_timeout = 5
health_check_min_success_rate = 0.8
health_check_max_response_time = 3.0

# é…ç½®ç®¡ç†
config_reload_interval = 30
enable_active_health_check = true

# è¯·æ±‚å¤„ç†
request_timeout = 120
max_retries = 3
retry_delay = 0.1
```

### ç”Ÿäº§ç¯å¢ƒé…ç½®

```toml
[servers]
servers = [
    # é«˜æ€§èƒ½ GPU æœåŠ¡å™¨
    { url = "http://gpu-server-1:8081", max_concurrent_requests = 8 },
    { url = "http://gpu-server-2:8081", max_concurrent_requests = 8 },

    # ä¸­ç­‰æ€§èƒ½ GPU æœåŠ¡å™¨
    { url = "http://gpu-server-3:8081", max_concurrent_requests = 4 },
    { url = "http://gpu-server-4:8081", max_concurrent_requests = 4 },

    # å¤‡ç”¨æœåŠ¡å™¨ (è¾ƒä½ä¼˜å…ˆçº§)
    { url = "http://backup-server-1:8081", max_concurrent_requests = 2 },
]

[config]
# ç”Ÿäº§ç¯å¢ƒå¥åº·æ£€æŸ¥ (æ›´ä¸¥æ ¼)
health_check_interval = 5
health_check_timeout = 3
health_check_min_success_rate = 0.95
health_check_max_response_time = 2.0
health_check_consecutive_failures = 2

# é…ç½®ç®¡ç†
config_reload_interval = 60
enable_active_health_check = true
failure_threshold = 2
auto_recovery_threshold = 120

# è¯·æ±‚å¤„ç† (ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–)
request_timeout = 180
max_retries = 5
retry_delay = 0.5
```

## ğŸ³ Docker éƒ¨ç½²

### 1. æ„å»º Docker é•œåƒ

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/xerrors/vllm-router.git
cd vllm-router

# æ„å»º Docker é•œåƒ
docker build -t vllm-router:latest .

# æˆ–æŒ‡å®šç‰ˆæœ¬
docker build -t vllm-router:v1.0.0 .
```

### 2. è¿è¡Œå®¹å™¨

#### å¼€å‘ç¯å¢ƒ
```bash
# åˆ›å»ºé…ç½®æ–‡ä»¶
cat > servers.toml << EOF
[servers]
servers = [
    { url = "http://host.docker.internal:8081", max_concurrent_requests = 3 },
    { url = "http://host.docker.internal:8082", max_concurrent_requests = 3 },
]

[config]
health_check_interval = 10
request_timeout = 60
max_retries = 3
EOF

# è¿è¡Œå®¹å™¨ (å¼€å‘æ¨¡å¼ï¼Œå¸¦æ§åˆ¶å°æ—¥å¿—)
docker run -d \
  --name vllm-router-dev \
  -p 8888:8888 \
  -v $(pwd)/servers.toml:/app/servers.toml \
  -e LOG_TO_CONSOLE=true \
  -e LOG_LEVEL=DEBUG \
  vllm-router:latest \
  run --console
```

#### ç”Ÿäº§ç¯å¢ƒ
```bash
# è¿è¡Œå®¹å™¨ (ç”Ÿäº§æ¨¡å¼ï¼Œæ— æ§åˆ¶å°æ—¥å¿—)
docker run -d \
  --name vllm-router-prod \
  -p 8888:8888 \
  -v $(pwd)/production-servers.toml:/app/servers.toml \
  -e LOG_TO_CONSOLE=false \
  -e LOG_LEVEL=INFO \
  --restart unless-stopped \
  --memory=512m \
  --cpus=1.0 \
  vllm-router:latest
```

### 3. Docker Compose éƒ¨ç½²

#### docker-compose.yml (åŸºç¡€ç‰ˆ)
```yaml
version: '3.8'

services:
  vllm-router:
    build: .
    container_name: vllm-router
    ports:
      - "8888:8888"
    volumes:
      - ./servers.toml:/app/servers.toml
      - ./logs:/app/logs
    environment:
      - LOG_TO_CONSOLE=false
      - LOG_LEVEL=INFO
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8888/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

#### docker-compose.yml (å®Œæ•´ç‰ˆ)
```yaml
version: '3.8'

services:
  vllm-router:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: vllm-router-prod
    ports:
      - "8888:8888"
    volumes:
      - ./production-servers.toml:/app/servers.toml
      - ./logs:/app/logs
      - /etc/localtime:/etc/localtime:ro
    environment:
      - LOG_TO_CONSOLE=false
      - LOG_LEVEL=INFO
      - CONFIG_PATH=/app/servers.toml
      - HOST=0.0.0.0
      - PORT=8888
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8888/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - vllm-network

  # å¯é€‰: Prometheus ç›‘æ§
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    networks:
      - vllm-network

  # å¯é€‰: Grafana å¯è§†åŒ–
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    restart: unless-stopped
    networks:
      - vllm-network

volumes:
  prometheus_data:
  grafana_data:

networks:
  vllm-network:
    driver: bridge
```

## â˜¸ï¸ Kubernetes éƒ¨ç½²

### 1. åŸºç¡€ Kubernetes é…ç½®

#### ConfigMap
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: vllm-router-config
  namespace: vllm-system
data:
  servers.toml: |
    [servers]
    servers = [
      { url = "http://vllm-server-1.vllm-system.svc.cluster.local:8081", max_concurrent_requests = 8 },
      { url = "http://vllm-server-2.vllm-system.svc.cluster.local:8081", max_concurrent_requests = 8 },
      { url = "http://vllm-server-3.vllm-system.svc.cluster.local:8081", max_concurrent_requests = 4 },
    ]

    [config]
    health_check_interval = 10
    health_check_timeout = 5
    health_check_min_success_rate = 0.9
    health_check_max_response_time = 3.0

    config_reload_interval = 60
    enable_active_health_check = true

    request_timeout = 120
    max_retries = 3
```

#### Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-router
  namespace: vllm-system
  labels:
    app: vllm-router
spec:
  replicas: 3  # é«˜å¯ç”¨éƒ¨ç½²
  selector:
    matchLabels:
      app: vllm-router
  template:
    metadata:
      labels:
        app: vllm-router
    spec:
      containers:
      - name: vllm-router
        image: vllm-router:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8888
          name: http
        env:
        - name: CONFIG_PATH
          value: "/etc/vllm-router/servers.toml"
        - name: LOG_TO_CONSOLE
          value: "false"
        - name: LOG_LEVEL
          value: "INFO"
        volumeMounts:
        - name: config
          mountPath: "/etc/vllm-router"
        - name: logs
          mountPath: "/app/logs"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8888
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: 8888
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 1
      volumes:
      - name: config
        configMap:
          name: vllm-router-config
      - name: logs
        emptyDir: {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - vllm-router
              topologyKey: kubernetes.io/hostname
```

#### Service
```yaml
apiVersion: v1
kind: Service
metadata:
  name: vllm-router-service
  namespace: vllm-system
  labels:
    app: vllm-router
spec:
  selector:
    app: vllm-router
  ports:
  - name: http
    port: 8888
    targetPort: 8888
  type: ClusterIP
```

#### Ingress
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: vllm-router-ingress
  namespace: vllm-system
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - vllm-router.yourdomain.com
    secretName: vllm-router-tls
  rules:
  - host: vllm-router.yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: vllm-router-service
            port:
              number: 8888
```

### 2. Helm Chart éƒ¨ç½²

#### åˆ›å»º Helm Chart
```bash
# åˆ›å»º Chart ç»“æ„
helm create vllm-router-chart
cd vllm-router-chart

# ç¼–è¾‘ values.yaml
cat > values.yaml << EOF
replicaCount: 3

image:
  repository: vllm-router
  tag: latest
  pullPolicy: Always

service:
  type: ClusterIP
  port: 8888

ingress:
  enabled: true
  hosts:
    - host: vllm-router.yourdomain.com
      paths: ["/"]
  tls: []

config:
  servers:
    - url: "http://vllm-server-1:8081"
      max_concurrent_requests: 8
    - url: "http://vllm-server-2:8081"
      max_concurrent_requests: 8

resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 250m
    memory: 256Mi

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80
EOF

# å®‰è£… Chart
helm install vllm-router ./vllm-router-chart -n vllm-system --create-namespace
```

## ğŸ”„ ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

### 1. é«˜å¯ç”¨é…ç½®

#### å¤šåŒºåŸŸéƒ¨ç½²
```yaml
# ä½¿ç”¨ Kubernetes éƒ¨ç½²å¤šåŒºåŸŸå®ä¾‹
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-router-us-east
  namespace: vllm-system
spec:
  replicas: 3
  template:
    spec:
      nodeSelector:
        topology.kubernetes.io/region: us-east
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-router-us-west
  namespace: vllm-system
spec:
  replicas: 3
  template:
    spec:
      nodeSelector:
        topology.kubernetes.io/region: us-west
```

#### è´Ÿè½½å‡è¡¡é…ç½®
```nginx
# Nginx è´Ÿè½½å‡è¡¡é…ç½®
upstream vllm_router_backend {
    least_conn;
    server vllm-router-1:8888 weight=3;
    server vllm-router-2:8888 weight=3;
    server vllm-router-3:8888 weight=2;

    # å¥åº·æ£€æŸ¥
    keepalive 32;
    keepalive_requests 1000;
    keepalive_timeout 60s;
}

server {
    listen 80;
    server_name vllm-router.yourdomain.com;

    location / {
        proxy_pass http://vllm_router_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # è¶…æ—¶é…ç½®
        proxy_connect_timeout 5s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;

        # å¥åº·æ£€æŸ¥
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }
}
```

### 2. ç›‘æ§å’Œæ—¥å¿—

#### Prometheus é…ç½®
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'vllm-router'
    static_configs:
      - targets: ['vllm-router:8888']
    metrics_path: '/metrics'
    scrape_interval: 10s
    scrape_timeout: 5s

  - job_name: 'vllm-servers'
    static_configs:
      - targets:
        - 'vllm-server-1:8081'
        - 'vllm-server-2:8081'
        - 'vllm-server-3:8081'
    metrics_path: '/metrics'
    scrape_interval: 15s
```

#### æ—¥å¿—é…ç½®
```bash
# æ—¥å¿—è½®è½¬é…ç½®
cat > logrotate.conf << EOF
/var/log/vllm-router/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    create 644 vllm-router vllm-router
    postrotate
        /usr/bin/docker exec vllm-router kill -USR1 $(cat /var/run/vllm-router.pid)
    endscript
}
EOF
```

### 3. å®‰å…¨é…ç½®

#### ç½‘ç»œå®‰å…¨
```yaml
# NetworkPolicy é…ç½®
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: vllm-router-network-policy
  namespace: vllm-system
spec:
  podSelector:
    matchLabels:
      app: vllm-router
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8888
  egress:
  - to: []
    ports:
    - protocol: TCP
      port: 8081  # vLLM æœåŠ¡å™¨ç«¯å£
```

#### ç¯å¢ƒå˜é‡å®‰å…¨
```bash
# ä½¿ç”¨ Kubernetes Secrets
kubectl create secret generic vllm-router-secrets \
  --from-literal=api-key=your-api-key \
  --from-literal=database-url=your-database-url \
  -n vllm-system

# åœ¨éƒ¨ç½²ä¸­å¼•ç”¨
env:
  - name: API_KEY
    valueFrom:
      secretKeyRef:
        name: vllm-router-secrets
        key: api-key
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### 1. å¥åº·æ£€æŸ¥æµ‹è¯•

```bash
# æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹
curl -f http://localhost:8888/health || echo "Health check failed"

# æµ‹è¯•è´Ÿè½½ç»Ÿè®¡
curl -s http://localhost:8888/load-stats | jq .

# æµ‹è¯•æ¨¡å‹åˆ—è¡¨
curl -s http://localhost:8888/v1/models | jq .
```

### 2. æ€§èƒ½æµ‹è¯•

```bash
# ä½¿ç”¨ wrk è¿›è¡Œå‹åŠ›æµ‹è¯•
wrk -t12 -c400 -d30s http://localhost:8888/health

# ä½¿ç”¨ ab è¿›è¡ŒåŸºå‡†æµ‹è¯•
ab -n 1000 -c 50 http://localhost:8888/health

# è‡ªå®šä¹‰æµ‹è¯•è„šæœ¬
cat > test_load_balancing.py << EOF
import asyncio
import aiohttp
import json

async def test_chat_completion():
    url = "http://localhost:8888/v1/chat/completions"
    payload = {
        "model": "llama3.1:8b",
        "messages": [{"role": "user", "content": "Hello!"}],
        "max_tokens": 50
    }

    async with aiohttp.ClientSession() as session:
        async with session.post(url, json=payload) as response:
            return await response.json()

async def run_tests():
    tasks = [test_chat_completion() for _ in range(100)]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    success_count = sum(1 for r in results if not isinstance(r, Exception))
    print(f"Success rate: {success_count}/{len(results)}")

asyncio.run(run_tests())
EOF
```

### 3. æ•…éšœè½¬ç§»æµ‹è¯•

```bash
# æ¨¡æ‹ŸæœåŠ¡å™¨æ•…éšœ
docker stop vllm-server-1

# è§‚å¯Ÿè·¯ç”±å™¨è¡Œä¸º
curl -s http://localhost:8888/health | jq '.servers[] | select(.healthy == false)'

# æ¢å¤æœåŠ¡å™¨
docker start vllm-server-1

# éªŒè¯è‡ªåŠ¨æ¢å¤
sleep 30
curl -s http://localhost:8888/health | jq '.servers[] | select(.url | contains("server-1"))'
```

## ğŸ“š æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **è¿æ¥è¶…æ—¶**
   ```bash
   # æ£€æŸ¥ç½‘ç»œè¿æ¥
   telnet vllm-server-1 8081

   # æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
   sudo ufw status
   sudo iptables -L
   ```

2. **é…ç½®æ–‡ä»¶é”™è¯¯**
   ```bash
   # éªŒè¯é…ç½®æ–‡ä»¶
   vllm-router check-config --config servers.toml

   # æ£€æŸ¥ TOML è¯­æ³•
   python -c "import toml; toml.load('servers.toml')"
   ```

3. **å†…å­˜ä¸è¶³**
   ```bash
   # æ£€æŸ¥å†…å­˜ä½¿ç”¨
   free -h

   # ç›‘æ§ Docker å®¹å™¨
   docker stats vllm-router

   # è°ƒæ•´å†…å­˜é™åˆ¶
   docker update --memory 1g vllm-router
   ```

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker logs -f vllm-router

# è¿‡æ»¤é”™è¯¯æ—¥å¿—
docker logs vllm-router 2>&1 | grep ERROR

# åˆ†æç»“æ„åŒ–æ—¥å¿—
cat logs/vllm-router-structured.log | jq '.time + " " + .level + " " + .message'
```

è¿™ä¸ªéƒ¨ç½²æŒ‡å—æä¾›äº†ä»å¼€å‘åˆ°ç”Ÿäº§çš„å®Œæ•´éƒ¨ç½²æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ Dockerã€Kubernetesã€ç›‘æ§é…ç½®ã€å®‰å…¨è®¾ç½®å’Œæ•…éšœæ’é™¤ç­‰å†…å®¹ã€‚